\subsection{Multiplicación por bloques}

    \def\model{ByBlocks}
    \def\analisisAmdahl{
    Podemos observar que el speed up teórico tiende al máximo speed-up
    mientras que el real nos muestra que no usa toda la paralelizacion ya que al
    pasar de 1 a 2 threads, el tiempo no cae a la mitad, y al pasar de 1 a 4 threads
    tampoco. Se puede ver que tiene un speed-up de casi 2 lo cual quiere decir que
    hace uso de la mitad.
    }
    \def\analisisGustafson{
    Podemos ver que estos resultados demuestran que la sección serie del
    problema se mantiene casi constante respecto de la sección paralela
    que varía en forma ascendente con el tamaño de los datos de entrada.
    Pero además podemos observar que hay mucha ineficiencia respecto del uso de
    la paralelización ya que al aumentar el trabajo en casi el doble usando
    dos procesadores debería tardar aproximadamente lo mismo. Sin embargo vemos
    que el tiempo paralelo se duplicó, lo cual muestra que hay un problema de
    comunicación al aumentar el paralelismo. Mas adelante explicaremos que el
    módulo Pool es ineficiente respecto del uso de recursos
    }
    \input{report/resultados_template.tex}
    \newpage
    \clearpage

\subsection{Multiplicación elemento por fila}

    \def\model{ElementByRowBlock}
    \def\analisisAmdahl{
    Podemos observar que el speed up teórico tiende al máximo speed-up
    mientras que el real nos muestra que no usa toda la paralelizacion ya que al
    pasar de 1 a 2 threads, el tiempo no cae a la mitad, y al pasar de 1 a 4 threads
    tampoco. Se puede ver que tiene un speed-up de casi 2 lo cual quiere decir que
    hace uso de la mitad.
    }
    \def\analisisGustafson{
    Podemos ver que estos resultados demuestran que la sección serie del
    problema se mantiene casi constante respecto de la sección paralela
    que varía en forma ascendente con el tamaño de los datos de entrada.
    Pero además podemos observar que hay mucha ineficiencia respecto del uso de
    la paralelización ya que al aumentar el trabajo en casi el doble usando
    dos procesadores debería tardar aproximadamente lo mismo. Sin embargo vemos
    que el tiempo paralelo se duplicó, lo cual muestra que hay un problema de
    comunicación al aumentar el paralelismo. Mas adelante explicaremos que el
    módulo Pool es ineficiente respecto del uso de recursos
    }
    \input{report/resultados_template.tex}
    \newpage
    \clearpage

\subsection{Multiplicación columna por fila}

    \def\model{ColumnByRow}
    \def\analisisAmdahl{
    Podemos observar que el speed up teórico tiende al máximo speed-up
    mientras que el real nos muestra que no usa toda la paralelizacion ya que al
    pasar de 1 a 2 threads, el tiempo no cae a la mitad, y al pasar de 1 a 4 threads
    tampoco. Se puede ver que tiene un speed-up de casi 2 lo cual quiere decir que
    hace uso de la mitad.
    }
    \def\analisisGustafson{
    Podemos ver que estos resultados demuestran que la sección serie del
    problema se mantiene casi constante respecto de la sección paralela
    que varía en forma ascendente con el tamaño de los datos de entrada.
    Pero además podemos observar que hay mucha ineficiencia respecto del uso de
    la paralelización ya que al aumentar el trabajo en casi el doble usando
    dos procesadores debería tardar aproximadamente lo mismo. Sin embargo vemos
    que el tiempo paralelo se duplicó, lo cual muestra que hay un problema de
    comunicación al aumentar el paralelismo. Mas adelante explicaremos que el
    módulo Pool es ineficiente respecto del uso de recursos
    }
    \input{report/resultados_template.tex}
    \newpage
    \clearpage

\subsection{Cblas e instrucciones vectorizadas}
    \def\text{Tiempo serie de multiplicacion en segundos}
    \def\path{dgemm.png}
    \def\scale{.6}
    \input{report/image.tex}

    Podemos decir que en general, las corridas con mapReduce, en el caso donde se
    uso un solo thread, si sumamos el tiempo paralelo y serie (que es todo serie
    ya que se usa un solo thread) nos da en promedio de los tres tipos de
    multiplicacion tardaron alrededor de 3 segundos. En cambio podemos ver que
    usando \code{cblas} tenemos un tiempo de 0.03 segundos y usando las
    instrucciones vectorizadas 0.36 segundos.\\
    De esta manera vemos que \code{cblas} y las instrucciones vectorizadas aprovechan
    mucho mejor el hardware para la realizacion de la misma operacion. Tambien es
    cierto que el map reduce hace uso de un modulo de \code{python} llamado
    \code{pool} que puede ser que sume latencia al momento de dividir el trabajo,
    pero cuando aumentamos mucho el volumen del trabajo se ve en los graficos que
    se aprovecha mejor la paralelizacion.
