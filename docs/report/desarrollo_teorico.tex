\subsection{Speed up}

Es la mejora en la velocidad de ejecución de una tarea ejecutada en dos
arquitecturas similares con diferentes recursos.\\
La noción de speedup fue establecida por la ley de Amdahl, que estaba
dirigida particularmente a la computación paralela. Sin embargo, la speedup se
puede usar más generalmente para mostrar el efecto en el rendimiento después de
cualquier mejora en los recursos.\\
De forma genérica se define como:
\begin{equation}
    \textbf{speed\_up} = \dfrac{Rendimiento\_con\_mejora}{Rendimiento\_sin\_mejora}
\end{equation}
En el caso de mejoras aplicadas a los tiempo de ejecución de una tarea:
\begin{equation}
    \textbf{speed\_up} = \dfrac{T\_ejecucion\_sin\_mejora}{T\_ejecucion\_con\_mejora}
\end{equation}

\subsection{Ley de Amdahl}

Utilizada para averiguar la mejora máxima de un sistema de información cuando
solo una parte de éste es mejorado.\\
Establece que la mejora obtenida en el rendimiento de un sistema debido a la
alteración de uno de sus componentes está limitada por la fracción de tiempo
que se utiliza dicho componente.\\

Suponiendo que nuestro algoritmo se divide en una parte secuencial \code{s}
u una parte paralelizable \code{p} y siendo \code{N} la cantidad de threads,
entonces podemos decir que:
\begin{equation}
    \textbf{speed\_up} = \dfrac{s+p}{s+\dfrac{p}{N}}
\end{equation}

Amdahl establece un límite superior al speedup que puede obtenerse al
introducir una mejora en un determinado algoritmo. Este límite superior está
determinado por la porción de la tarea sobre la que se aplique la mejora.
Entonces si tomamos la ecuacion anterior y calculamos el limite de la misma con
\code{N} tendiendo a infinito tenemos:
\begin{equation}
    \textbf{speed\_up\_max} = 1 + \dfrac{p}{s}
\end{equation}
\newpage

\subsection{Ley de Gustafson}

Establece que cualquier problema suficientemente grande puede ser eficientemente
paralelizado. La ley de Gustafson está muy ligada a la ley de Amdahl, que pone
límite a la mejora que se puede obtener gracias a la paralelización, dado un
conjunto de datos de tamaño fijo, ofreciendo así una visión pesimista del
procesamiento paralelo. Por el contrario la ley de Gustafson  propone realizar
mas trabajo con la misma cantidad de recursos, de esta manera aprovecho la
paralelizacion para calcular mas cosas.\\

Entonces siendo \code{s} el tiempo de la ejecucucion de la seccion serie, siendo
\code{p} el tiempo de la ejecucion de la seccion paralela y siendo \code{N} la
cantidad de procesadores podemos calcular el speed up como:
\begin{equation}
    \textbf{speed\_up} = \dfrac{s+p*N}{s+p}
\end{equation}

\subsection{Map-reduce}

MapReduce es una técnica de procesamiento y un programa modelo de computación
distribuida. El algoritmo MapReduce contiene dos tareas importantes.\\\\
\code{Map} toma un conjunto de datos y se convierte en otro conjunto de datos, en el
que los elementos se dividen en tuplas \code{(pares: clave, valor)}.\\\\
En el medio ocurre la fase de agrupamiento la cual consiste de agrupar los valores
con misma clave en un vector para entregarle a la fase de reduce un conjunto de
tuplas \code{(clave, valores)} donde en este caso el valor son todos los valores
en una lista.\\\\
\code{Reduce} recibe un conjunto de tuplas \code{(clave, valores)} donde el valor
es una lista de todos los valores que tenian la misma clave. Entonces reduce
aplica una funcion a todos estos valores para retornar un unico valor y asi
devolver un conjunto de tuplas \code{(clave, valor)}\\\\
La principal ventaja de MapReduce es que es fácil de escalar procesamiento de
datos en múltiples nodos.\\
De acuerdo a este modelo, basado en la programación funcional, la tarea del
usuario consiste en la definición de una función map y una función reduce y
definidas estas funciones, el procesamiento es fácilmente paralelizable, ya sea
en una sola máquina o en un cluster.\\

\subsection{High Performance Portable Libraries for Dense Linear Algebra}
    \def\text{overall picture}
    \def\path{overall.png}
    \def\scale{.6}
    \input{report/image.tex}
    \subsubsection{LAPACK}
        LAPACK está escrito en Fortran 90 y proporciona rutinas para resolver
        sistemas de ecuaciones lineales simultáneas, soluciones de mínimos
        cuadrados de sistemas de ecuaciones lineales, problemas de valores propios y
        problemas de valores singulares. También se proporcionan las factorizaciones
        matriciales asociadas (LU, Cholesky, QR, SVD, Schur, Schur generalizado),
        al igual que los cálculos relacionados, tales como la reordenación de las
        factorizaciones de Schur y la estimación de los números de condición. Se
        manejan matrices densas y con bandas, pero no matrices dispersas generales.
        En todas las áreas, se proporciona una funcionalidad similar para matrices
        reales y complejas, con precisión simple y doble.

    \subsubsection{ScaLAPACK}
        Es una liberia de rutinas de álgebra lineal de alto rendimiento para máquinas
        de memoria distribuida en paralelo. ScaLAPACK resuelve sistemas lineales
        densos y en bandas, problemas de mínimos cuadrados, problemas de valores
        propios y problemas de valores singulares. Las ideas clave incorporadas en
        ScaLAPACK incluyen el uso de:
        \begin{itemize}
            \item Una distribución de datos de bloques cíclicos para matrices densas
            y una distribución de datos de bloques para matrices en bandas,
            parametrizable en tiempo de ejecución.
            \item Algoritmos de partición de bloque para asegurar altos niveles de
            reutilización de datos.
            \item Componentes modulares de bajo nivel bien diseñados que simplifican
            la tarea de paralelizar las rutinas de alto nivel haciendo que su código
            fuente sea el mismo que en el caso secuencial.
        \end{itemize}

    \subsubsection{CBLAS}
        BLAS (Subprogramas de Álgebra Lineal Básica) son rutinas que proporcionan
        bloques de construcción estándar para realizar operaciones básicas de
        vectores y matrices. Las BLAS de nivel 1 realizan operaciones escalares,
        vectoriales y vectoriales, las BLAS de nivel 2 realizan operaciones de
        vectores matriciales y las BLAS de nivel 3 realizan operaciones
        de matriz-matriz. Debido a que los BLAS son eficientes, portátiles y
        ampliamente disponibles, se usan comúnmente en el desarrollo de software
        de álgebra lineal de alta calidad, LAPACK, por ejemplo.\\
        CBLAS es una interfaz de lenguaje C para BLAS.\\
        Nosotros estaremos usando Cblas para este tp.

\subsection{Instrucciones vectoriales MMX}
    MMX es un Conjunto de instrucciones SIMD diseñado por Intel e introducido en
    1997 en sus microprocesadores Pentium MMX. Fue desarrollado a partir de un
    set introducido en el Intel i860. Ha sido soportado por la mayoría de
    fabricantes de microprocesadores x86 desde entonces.

    Fue presentado como un acrónimo de MultiMedia eXtension o Multiple Math o
    Matrix Math eXtension, pero oficialmente sólo es un juego de consonantes
    sin significado, usado con la única intención de poder poner cortapisas
    legales de marca registrada a los desarrollos de terceros que trataran de
    usarlo.
